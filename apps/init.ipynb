{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from models import face_describer_server, nn, dataloader, face_track_server\n",
    "from configs import configs\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/gregoire/Documents/INF8225/projet/face_recognition\n/home/gregoire/Documents/INF8225/projet/face_recognition\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FaceTracker Server] Found 1 faces!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[[[ 60,  81, 104],\n         [ 59,  82, 105],\n         [ 77, 107, 132],\n         ...,\n         [ 45,  66,  90],\n         [ 60,  78, 103],\n         [ 83, 107, 132]],\n\n        [[ 68,  89, 114],\n         [ 95, 119, 145],\n         [ 93, 119, 145],\n         ...,\n         [ 74,  91, 108],\n         [ 49,  67,  88],\n         [ 84, 104, 125]],\n\n        [[ 87, 114, 140],\n         [ 76, 103, 128],\n         [101, 127, 152],\n         ...,\n         [ 56,  70,  89],\n         [ 66,  81, 100],\n         [ 56,  70,  88]],\n\n        ...,\n\n        [[132,  78,  47],\n         [115,  73,  50],\n         [119,  91,  86],\n         ...,\n         [172, 173, 175],\n         [156, 168, 173],\n         [167, 165, 169]],\n\n        [[130,  83,  51],\n         [134,  93,  67],\n         [138, 115, 102],\n         ...,\n         [161, 159, 164],\n         [169, 177, 177],\n         [151, 151, 157]],\n\n        [[142,  98,  67],\n         [126,  82,  51],\n         [121,  94,  83],\n         ...,\n         [156, 155, 161],\n         [161, 166, 165],\n         [159, 163, 168]]]], dtype=uint8), 0.1]\n[Base Server] Running inference...\n"
     ]
    }
   ],
   "source": [
    "print(configs.BASE_PATH)\n",
    "print('/'.join(os.getcwd().split('/')))\n",
    "face_describer = face_describer_server.FDServer(\n",
    "        model_fp=configs.face_describer_model_fp,\n",
    "        input_tensor_names=configs.face_describer_input_tensor_names,\n",
    "        output_tensor_names=configs.face_describer_output_tensor_names,\n",
    "        device=configs.face_describer_device)\n",
    "face_tracker = face_track_server.FaceTrackServer()\n",
    "data = dataloader.DataLoader(face_describer)\n",
    "img = cv2.imread(\"./tests/jennifer-lawrence_gettyimages-626382596jpg.jpg\")\n",
    "face_tracker.process(img)\n",
    "test_face = face_tracker.get_faces()[0]\n",
    "X_test = data.getFeatures(test_face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.load_data(configs.db_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model = nn.Model(output_shape=len(np.unique(data.Y)))\n",
    "    #nn_model = nn.Model(path_to_model=\"/pretrained/init.hdf5\")\n",
    "    nn_model.train_model_from_data(data.X, data.Y)\n",
    "    nn_model.save_model(configs.model_pretrained_path + \"init\" + configs.save_model_format)\n",
    "    nn_model.model.summary()\n",
    "\n",
    "    with nn_model.new_Graph.as_default():\n",
    "        Y = nn_model.model.predict(np.matrix(X_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
